{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959488b9",
   "metadata": {},
   "source": [
    "Para crear y analizar un modelo lineal en python, precisamos de varias librerías para cada uno de los procesos de su estudio. \n",
    "Antes de nada, hay que preprocesar los datos, de lo que se encargan las funciones creadas en el primer sprint. Una vez estén preprocesados, tenemos que crear el modelo, entrenarlo y evaluarlo mediante una de las siguientes librerías: **scikit-learn** o **statsmodels**\n",
    "Estas son las dos librerías más dominantes en modelos lineales, pero también podemos usar otras, como **linearmodels**(librería más enfocada a la economía) o **PyTorch**(librería más compleja y avanzada que se usa en deeplearning, machine learning...)\n",
    "\n",
    "Princpalmente estudiaremos scikit y statsmodels, pero al final también miraremos un poco las otras dos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3c972",
   "metadata": {},
   "source": [
    "1. CREAR UN MODELO\n",
    "    - Con scikit.learn, una vez tenemos los datos divididos en entrenamiento y test, debemos usar la siguiente función: LinearRegression()\n",
    "\n",
    "    - En statsmodels, antes de crar el modelo, si queremos que b0 (intercepto / término constante) no sea 0, tenemos que usar sobre la columna de entrada la función:\n",
    "    x = sm.add_constant(cte)\n",
    "    Tras esto, para crear el modelo se usa:\n",
    "    OLS(y, x)\n",
    "    Sea x la columna de entrada e y la de salida\n",
    "\n",
    "2. ENTRENAR EL MODELO\n",
    "En las dos librerías se utiliza el mismo nombre de método de su clase modelo, pero la de scikit recibe parámetros (pues no los recibió antes):\n",
    "model.fit(x, y)\n",
    "Y la de statsmodels no recibe las columnas:\n",
    "model.fit()\n",
    "\n",
    "3. ANÁLISIS DEL MODELO\n",
    "En esta parte es donde estas librerías se diferencian más, pues statsmodels está orientada cara un análisis estadístico profundo de las características de la regresión, mientras que scikit es más simple.\n",
    "    - En scikit.learn se usan las siguientes funciones para análisis:\n",
    "    model.score(x, y) --> muestra el coeficiente de determinación (R^2) \n",
    "    model.intercept_ --> muestra el valor de b0 (término constante)\n",
    "    model.coef_ --> muestra el valor de b1 (monotonía de y cuando crece x)\n",
    "\n",
    "    - En statsmodels podemos obtener muchos más datos solo con usar:\n",
    "    model.summary() --> print con gran cantidsd de datos estadísticos del modelo\n",
    "    También podemos extraer valores especificos, por ejemplo:\n",
    "    model.rsquared --> coeficiente de determinación\n",
    "\n",
    "4. PREDICCIÓN\n",
    "    - En sickit.learn se usa la función model.predict(x), donde x son los datos de test, y el array que devuelve son los valores esperados de y, la salida. Estos los podemos comparar con los datos originales que se obtienen con el datasplit.\n",
    "    También podemos introducir cualquier array de valores para ver que resultado sale.\n",
    "\n",
    "    - En statsmodels se usa model.fittedvalues si quieres obtener las preedicciones del array con el que fue entrenado, y usas model.predict(x) si quieres introducir un nuevo array x a predecir.\n",
    "\n",
    "Veamos un ejemplo de cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32470012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrada: \n",
      " [[ 5]\n",
      " [15]\n",
      " [25]\n",
      " [35]\n",
      " [45]\n",
      " [55]] \n",
      " \n",
      " Datos de salida: [ 10  30  50  70  90 110]\n",
      "coeficiente de determinación: 1.0 \n",
      " término constante: 0.0        \n",
      " crecimiento: [2.]\n",
      " \n",
      " valores predecidos: [ 2.  8. 20. 22. 30.]\n"
     ]
    }
   ],
   "source": [
    "#Modelo de ejemplo de sklearn\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Columna de entrada\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "#Es necesario el reshape porque debe tener una columna y tantas filas como columnas de y\n",
    "\n",
    "#Columna de salida\n",
    "y = np.array([10, 30, 50, 70, 90, 110])\n",
    "\n",
    "print(f\"Datos de entrada: \\n {x} \\n \\n Datos de salida: {y}\")\n",
    "\n",
    "#Creamos el modelo\n",
    "model = LinearRegression()\n",
    "\n",
    "#Entrenamos (ajuste) el modelo con los datos de antes\n",
    "model.fit(x, y)\n",
    "\n",
    "#Análisis de datos\n",
    "r2 = model.score(x, y)\n",
    "print(f\"coeficiente de determinación: {r2} \\n término constante: {model.intercept_} \\\n",
    "       \\n crecimiento: {model.coef_}\")\n",
    "\n",
    "#Predicción del modelo\n",
    "xTest = np.array([1, 4, 10, 11, 15]).reshape((-1, 1))\n",
    "yPred = model.predict(xTest)\n",
    "print(f\"\\n valores predichos: {yPred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee7ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrada: \n",
      " [ 5 15 25 35 45 55] \n",
      "\n",
      " Datos de salida: [ 10  30  50  70  90 110]\n",
      "\n",
      "--- Resumen estadístico del modelo ---\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                       inf\n",
      "Date:                Mon, 20 Oct 2025   Prob (F-statistic):               0.00\n",
      "Time:                        21:39:43   Log-Likelihood:                    inf\n",
      "No. Observations:                   6   AIC:                              -inf\n",
      "Df Residuals:                       4   BIC:                              -inf\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const               0          0        nan        nan           0           0\n",
      "x1             2.0000          0        inf      0.000       2.000       2.000\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                     nan\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                  nan\n",
      "Skew:                             nan   Prob(JB):                          nan\n",
      "Kurtosis:                         nan   Cond. No.                         69.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Valores predichos: [ 2.  8. 20. 22. 30.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beltr\\miniconda3\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 6 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "c:\\Users\\beltr\\miniconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1871: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return self.mse_model/self.mse_resid\n",
      "c:\\Users\\beltr\\miniconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "c:\\Users\\beltr\\miniconda3\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:50: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dw = np.sum(diff_resids**2, axis=axis) / np.sum(resids**2, axis=axis)\n"
     ]
    }
   ],
   "source": [
    "# Modelo de ejemplo con statsmodels\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Columna de entrada (variable independiente)\n",
    "x = np.array([5, 15, 25, 35, 45, 55])\n",
    "# Columna de salida (variable dependiente)\n",
    "y = np.array([10, 30, 50, 70, 90, 110])\n",
    "\n",
    "print(f\"Datos de entrada: \\n {x} \\n\\n Datos de salida: {y}\")\n",
    "\n",
    "# En statsmodels debemos agregar una columna de 1s para el intercepto (β₀)\n",
    "x_con_constante = sm.add_constant(x)  # añade la columna de 1s\n",
    "\n",
    "# Creamos el modelo de mínimos cuadrados ordinarios (OLS)\n",
    "modelo = sm.OLS(y, x_con_constante)\n",
    "\n",
    "# Ajustamos (entrenamos) el modelo\n",
    "resultado = modelo.fit()\n",
    "\n",
    "# Análisis de resultados\n",
    "print(\"\\n--- Resumen estadístico del modelo ---\")\n",
    "print(resultado.summary())\n",
    "\n",
    "# Predicciones\n",
    "xTest = np.array([1, 4, 10, 11, 15])\n",
    "xTest_con_constante = sm.add_constant(xTest)\n",
    "yPred = resultado.predict(xTest_con_constante)\n",
    "\n",
    "print(f\"\\nValores predichos: {yPred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b20fd9",
   "metadata": {},
   "source": [
    "Pese a que statsmodels ofrece más información estadística, sklearn tiene muchos recursos de aprendizaje y es más simple; por lo que es más adecuado para este proyecto, ya que no se focaliza tanto en el análisis de los datos y es más entendible tanto para el cliente (en caso de tener que explicar algo) como para los desarrolladores.\n",
    "\n",
    "Las otras dos librerías quedan fuera de la cuestión por centrarse más en otros ámbitos, pero tienen una funcionalidad similar a sklearn y statsmodels en la creación de regresiones lineales (mismo proceso de creación, ajuste, análisis y predicción).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Fuentes: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
    "\n",
    "https://realpython.com/linear-regression-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
